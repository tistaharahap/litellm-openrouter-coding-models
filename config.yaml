# LiteLLM Proxy Configuration
# This configuration sets up a proxy server for multiple AI models

model_list:
  - model_name: qwen3-coder
    litellm_params:
      model: openrouter/qwen/qwen3-coder
      api_key: os.environ/OPENROUTER_API_KEY
      drop_params: true
  - model_name: qwen3-coder-free
    litellm_params:
      model: openrouter/qwen/qwen3-coder:free
      api_key: os.environ/OPENROUTER_API_KEY
      drop_params: true
  - model_name: glm-air-4.5-free
    litellm_params:
      model: openrouter/z-ai/glm-4.5-air:free
      api_key: os.environ/OPENROUTER_API_KEY
      drop_params: true
  - model_name: gemini-2.5-flash
    litellm_params:
      model: openrouter/google/gemini-2.5-flash
      api_key: os.environ/OPENROUTER_API_KEY
      drop_params: true
  - model_name: deepseek-chat-v3
    litellm_params:
      model: openrouter/deepseek/deepseek-chat-v3-0324
      api_key: os.environ/OPENROUTER_API_KEY
      drop_params: true
  - model_name: deepseek-v3.1-free
    litellm_params:
      model: openrouter/deepseek/deepseek-chat-v3.1:free
      api_key: os.environ/OPENROUTER_API_KEY
      drop_params: true
  - model_name: gemini-2.5-pro
    litellm_params:
      model: openrouter/google/gemini-2.5-pro
      api_key: os.environ/OPENROUTER_API_KEY
      drop_params: true
  - model_name: kimi-k2
    litellm_params:
      model: openrouter/moonshotai/kimi-k2
      api_key: os.environ/OPENROUTER_API_KEY
      drop_params: true
  - model_name: gpt-5
    litellm_params:
      model: openai/gpt-5
      api_key: os.environ/OPENAI_API_KEY
      drop_params: true
      additional_drop_params: ["max_tokens"]
  - model_name: uae-k2
    litellm_params:
      model: ollama/hf.co/DevQuasar/LLM360.K2-Think-GGUF:Q4_K_M
      api_base: os.environ/OLLAMA_BASE_URL
      drop_params: true
  - model_name: deepseek-coder
    litellm_params:
      model: ollama/deepseek-coder:33b
      api_base: os.environ/OLLAMA_BASE_URL
      drop_params: true
  - model_name: deepseek-coder-v2
    litellm_params:
      model: ollama/deepseek-coder-v2:16b
      api_base: os.environ/OLLAMA_BASE_URL
      drop_params: true
  - model_name: gpt-oss
    litellm_params:
      model: ollama/gpt-oss:20b
      api_base: os.environ/OLLAMA_BASE_URL
      drop_params: true

# General settings
general_settings:
  # Master key for authenticating to the proxy
  master_key: os.environ/LITELLM_MASTER_KEY

  # Set custom port (default is 4000)
  port: 4000

  # Enable CORS for web requests
  cors: true

  # Set request timeout (in seconds)
  request_timeout: 600

  # Enable streaming responses
  stream: true

  # Batch write setting
  proxy_batch_write_at: 60

router_settings:
  redis_host: os.environ/REDIS_HOST
  redis_port: os.environ/REDIS_PORT

litellm_settings:
  set_verbose: true
